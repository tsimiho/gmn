{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from itertools import zip_longest\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import networkx as nx\n",
    "from torch.nn import Linear\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.functional import cosine_similarity\n",
    "from torch.optim import Adam\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import BatchNorm, MessagePassing, TopKPooling\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "from torch_geometric.utils import degree, from_networkx, to_networkx\n",
    "from torch_scatter import scatter_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mutag(\n",
    "    graph1,\n",
    "    graph2=None,\n",
    "    original_x1=None,\n",
    "    perm1=None,\n",
    "    original_x2=None,\n",
    "    perm2=None,\n",
    "    with_labels=False,\n",
    "):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import networkx as nx\n",
    "    import matplotlib\n",
    "    import matplotlib.patches as mpatches\n",
    "    from torch_geometric.utils import to_networkx\n",
    "\n",
    "    colormap = matplotlib.colormaps.get_cmap(\"Pastel1\")\n",
    "\n",
    "    color_map = {\n",
    "        0: colormap(0),  # C\n",
    "        1: colormap(1),  # O\n",
    "        2: colormap(2),  # Cl\n",
    "        3: colormap(3),  # H\n",
    "        4: colormap(4),  # N\n",
    "        5: colormap(5),  # F\n",
    "        6: colormap(6),  # Br\n",
    "        7: colormap(7),  # S\n",
    "        8: colormap(8),  # P\n",
    "        9: colormap(9),  # I\n",
    "        \"other\": \"gray\",\n",
    "    }\n",
    "\n",
    "    atom_types = {\n",
    "        0: \"C\",\n",
    "        1: \"O\",\n",
    "        2: \"Cl\",\n",
    "        3: \"H\",\n",
    "        4: \"N\",\n",
    "        5: \"F\",\n",
    "        6: \"Br\",\n",
    "        7: \"S\",\n",
    "        8: \"P\",\n",
    "        9: \"I\",\n",
    "    }\n",
    "\n",
    "    def plot_single_graph(graph, ax, original_x=None, perm=None):\n",
    "        G = to_networkx(graph, to_undirected=True)\n",
    "\n",
    "        node_colors = []\n",
    "        node_labels = {}\n",
    "\n",
    "        if original_x is not None and perm is not None:\n",
    "            mapped_x = original_x[perm[: graph.num_nodes]]\n",
    "            for node in range(graph.num_nodes):\n",
    "                one_hot = mapped_x[node].tolist()\n",
    "                try:\n",
    "                    node_type = one_hot.index(1)\n",
    "                except ValueError:\n",
    "                    node_type = \"other\"\n",
    "                node_colors.append(color_map.get(node_type, \"gray\"))\n",
    "                node_labels[node] = perm[node].item()\n",
    "        else:\n",
    "            for node in range(graph.num_nodes):\n",
    "                one_hot = graph.x[node].tolist()\n",
    "                try:\n",
    "                    node_type = one_hot.index(1)\n",
    "                except ValueError:\n",
    "                    node_type = \"other\"\n",
    "                node_colors.append(color_map.get(node_type, \"gray\"))\n",
    "                node_labels[node] = perm[node].item() if perm is not None else node\n",
    "\n",
    "        pos = nx.spring_layout(G)\n",
    "        nx.draw(\n",
    "            G,\n",
    "            pos,\n",
    "            node_color=node_colors,\n",
    "            with_labels=with_labels,\n",
    "            labels=node_labels,\n",
    "            node_size=500,\n",
    "            font_weight=\"bold\",\n",
    "            ax=ax,\n",
    "        )\n",
    "\n",
    "    legend_handles = [\n",
    "        mpatches.Patch(color=colormap(0), label=\"C\"),\n",
    "        mpatches.Patch(color=colormap(1), label=\"O\"),\n",
    "        mpatches.Patch(color=colormap(2), label=\"Cl\"),\n",
    "        mpatches.Patch(color=colormap(3), label=\"H\"),\n",
    "        mpatches.Patch(color=colormap(4), label=\"N\"),\n",
    "        mpatches.Patch(color=colormap(5), label=\"F\"),\n",
    "        mpatches.Patch(color=colormap(6), label=\"Br\"),\n",
    "        mpatches.Patch(color=colormap(7), label=\"S\"),\n",
    "        mpatches.Patch(color=colormap(8), label=\"P\"),\n",
    "        mpatches.Patch(color=colormap(9), label=\"I\"),\n",
    "        mpatches.Patch(color=\"gray\", label=\"Other\"),\n",
    "    ]\n",
    "\n",
    "    if graph2 is None:\n",
    "        fig, ax = plt.subplots(figsize=(8, 8))\n",
    "        plot_single_graph(graph1, ax, original_x1, perm1)\n",
    "    else:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(24, 16))\n",
    "        plot_single_graph(graph1, axes[0], original_x1, perm1)\n",
    "        plot_single_graph(graph2, axes[1], original_x2, perm2)\n",
    "\n",
    "    fig.legend(handles=legend_handles, loc=\"lower left\", title=\"Node Types\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_cosine_similarity(a, b):\n",
    "    a_norm = a / torch.norm(a, dim=1).unsqueeze(-1)\n",
    "    b_norm = b / torch.norm(b, dim=1).unsqueeze(-1)\n",
    "    res = torch.matmul(a_norm, b_norm.transpose(-2, -1))\n",
    "    return res\n",
    "\n",
    "\n",
    "def compute_cross_attention(x_i, x_j):\n",
    "    a = pairwise_cosine_similarity(x_i, x_j)\n",
    "    a_i = F.softmax(a, dim=1)\n",
    "    a_j = F.softmax(a, dim=0)\n",
    "    att_i = torch.matmul(a_i, x_j)\n",
    "    att_j = torch.matmul(a_j.T, x_i)\n",
    "    return att_i, att_j, a_i, a_j\n",
    "\n",
    "\n",
    "def batch_block_pair_attention(data, batch, n_graphs):\n",
    "    all_attention_x = []\n",
    "    all_attention_y = []\n",
    "    all_a_i = []\n",
    "    all_a_j = []\n",
    "\n",
    "    for i in range(0, n_graphs, 2):\n",
    "        x_i = data[batch == i]\n",
    "        x_j = data[batch == i + 1]\n",
    "\n",
    "        attention_x, attention_y, a_i, a_j = compute_cross_attention(x_i, x_j)\n",
    "\n",
    "        all_attention_x.append(attention_x)\n",
    "        all_attention_y.append(attention_y)\n",
    "        all_a_i.append(a_i)\n",
    "        all_a_j.append(a_j)\n",
    "\n",
    "    result_x = torch.cat(all_attention_x, dim=0)\n",
    "    result_y = torch.cat(all_attention_y, dim=0)\n",
    "\n",
    "    result = torch.cat([result_x, result_y], dim=0)\n",
    "\n",
    "    return result, all_a_i, all_a_j\n",
    "\n",
    "\n",
    "def create_batch(sizes):\n",
    "    sizes = sizes.tolist()\n",
    "    sizes = list(map(int, sizes))\n",
    "    batch = []\n",
    "    for i, size in enumerate(sizes):\n",
    "        batch.extend([i] * size)\n",
    "    batch = torch.tensor(batch, dtype=torch.int64)\n",
    "    return batch\n",
    "\n",
    "\n",
    "def create_graph_pairs(dataset, num_pairs):\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    for _ in range(num_pairs):\n",
    "        idx1, idx2 = random.sample(range(len(dataset)), 2)\n",
    "        graph1, graph2 = dataset[idx1], dataset[idx2]\n",
    "\n",
    "        label = 1 if graph1.y == graph2.y else -1\n",
    "        pairs.append((graph1, graph2))\n",
    "        labels.append(label)\n",
    "    return pairs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphMatchingConvolution(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels, args, aggr=\"add\"):\n",
    "        super(GraphMatchingConvolution, self).__init__(aggr=aggr)\n",
    "        self.args = args\n",
    "        self.lin_node = torch.nn.Linear(in_channels, out_channels)\n",
    "        self.lin_message = torch.nn.Linear(out_channels * 2, out_channels)\n",
    "        self.lin_passing = torch.nn.Linear(out_channels + in_channels, out_channels)\n",
    "        self.batch_norm = BatchNorm(out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x_transformed = self.lin_node(x)\n",
    "        return self.propagate(edge_index, x=x_transformed, original_x=x, batch=batch)\n",
    "\n",
    "    def message(self, edge_index_i, x_i, x_j):\n",
    "        x = torch.cat([x_i, x_j], dim=1)\n",
    "        m = self.lin_message(x)\n",
    "        return m\n",
    "\n",
    "    def update(self, aggr_out, edge_index, x, original_x, batch):\n",
    "        n_graphs = torch.unique(batch).shape[0]\n",
    "        cross_graph_attention, a_x, a_y = batch_block_pair_attention(\n",
    "            original_x, batch, n_graphs\n",
    "        )\n",
    "        attention_input = original_x - cross_graph_attention\n",
    "        aggr_out = self.lin_passing(torch.cat([aggr_out, attention_input], dim=1))\n",
    "        aggr_out = self.batch_norm(aggr_out)\n",
    "\n",
    "        norms = torch.norm(aggr_out, p=2, dim=1)\n",
    "        cross_attention_sums = cross_graph_attention.sum(dim=1)\n",
    "\n",
    "        return (\n",
    "            aggr_out,\n",
    "            edge_index,\n",
    "            batch,\n",
    "            (\n",
    "                attention_input,\n",
    "                cross_graph_attention,\n",
    "                a_x,\n",
    "                a_y,\n",
    "                norms,\n",
    "                cross_attention_sums,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "\n",
    "class GraphAggregator(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, args):\n",
    "        super(GraphAggregator, self).__init__()\n",
    "        self.lin = torch.nn.Linear(in_channels, out_channels)\n",
    "        self.lin_gate = torch.nn.Linear(in_channels, out_channels)\n",
    "        self.lin_final = torch.nn.Linear(out_channels, out_channels)\n",
    "        self.args = args\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x_states = self.lin(x)\n",
    "        x_gates = torch.nn.functional.softmax(self.lin_gate(x), dim=1)\n",
    "        x_states = x_states * x_gates\n",
    "        x_states = scatter_mean(x_states, batch, dim=0)\n",
    "        x_states = self.lin_final(x_states)\n",
    "        return x_states\n",
    "\n",
    "\n",
    "class GraphMatchingNetwork(torch.nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(GraphMatchingNetwork, self).__init__()\n",
    "        self.args = args\n",
    "        self.margin = self.args.margin\n",
    "        if args.n_classes > 2:\n",
    "            self.f1_average = \"micro\"\n",
    "        else:\n",
    "            self.f1_average = \"binary\"\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        self.layers.append(\n",
    "            GraphMatchingConvolution(self.args.feat_dim, self.args.dim, args)\n",
    "        )\n",
    "        for _ in range(self.args.num_layers - 1):\n",
    "            self.layers.append(\n",
    "                GraphMatchingConvolution(self.args.dim, self.args.dim, args)\n",
    "            )\n",
    "        self.aggregator = GraphAggregator(self.args.dim, self.args.dim, self.args)\n",
    "        self.layer_outputs = []\n",
    "        self.layer_cross_attentions = []\n",
    "        self.mincut = []\n",
    "        self.mlp = torch.nn.Sequential()\n",
    "        self.args.n_clusters = args.n_clusters\n",
    "        self.mlp.append(Linear(self.args.dim, self.args.n_clusters))\n",
    "        self.topk_outputs = []\n",
    "        self.norms_per_layer = []\n",
    "        self.attention_sums_per_layer = []\n",
    "\n",
    "    def compute_emb(\n",
    "        self, feats, edge_index, batch, sizes_1, sizes_2, edge_index_1, edge_index_2\n",
    "    ):\n",
    "\n",
    "        topk_pooling = TopKPooling(\n",
    "            self.args.dim, ratio=min(sizes_1.item(), sizes_2.item())\n",
    "        )\n",
    "        for i in range(self.args.num_layers):\n",
    "            (\n",
    "                feats,\n",
    "                edge_index,\n",
    "                batch,\n",
    "                (\n",
    "                    attention_input,\n",
    "                    cross_graph_attention,\n",
    "                    a_x,\n",
    "                    a_y,\n",
    "                    norms,\n",
    "                    attention_sums,\n",
    "                ),\n",
    "            ) = self.layers[i](feats, edge_index, batch)\n",
    "\n",
    "            x_1 = feats[: sizes_1.item(), :]\n",
    "            x_2 = feats[sizes_1.item() : sizes_1.item() + sizes_2.item(), :]\n",
    "\n",
    "            norms_1 = norms[: sizes_1.item()]\n",
    "            norms_2 = norms[sizes_1.item() : sizes_1.item() + sizes_2.item()]\n",
    "\n",
    "            attention_sums_1 = attention_sums[: sizes_1.item()]\n",
    "            attention_sums_2 = attention_sums[\n",
    "                sizes_1.item() : sizes_1.item() + sizes_2.item()\n",
    "            ]\n",
    "\n",
    "            x_pooled_1, edge_index_pooled_1, _, _, perm1, score1 = topk_pooling(\n",
    "                x_1,\n",
    "                edge_index_1,\n",
    "            )\n",
    "            x_pooled_2, edge_index_pooled_2, _, _, perm2, score2 = topk_pooling(\n",
    "                x_2,\n",
    "                edge_index_2,\n",
    "            )\n",
    "\n",
    "            self.topk_outputs.append(\n",
    "                (\n",
    "                    (x_pooled_1, edge_index_pooled_1, perm1, score1),\n",
    "                    (x_pooled_2, edge_index_pooled_2, perm2, score2),\n",
    "                )\n",
    "            )\n",
    "            self.layer_cross_attentions.append((cross_graph_attention, a_x, a_y))\n",
    "            self.layer_outputs.append((x_1, edge_index_1, x_2, edge_index_2))\n",
    "            self.norms_per_layer.append((norms_1, norms_2))\n",
    "            self.attention_sums_per_layer.append((attention_sums_1, attention_sums_2))\n",
    "\n",
    "        feats = self.aggregator(feats, edge_index, batch)\n",
    "        return feats, edge_index, batch\n",
    "\n",
    "    def combine_pair_embedding(\n",
    "        self, feats_1, edge_index_1, feats_2, edge_index_2, sizes_1, sizes_2\n",
    "    ):\n",
    "        feats = torch.cat([feats_1, feats_2], dim=0)\n",
    "        max_node_idx_1 = sizes_1.sum()\n",
    "        edge_index_2_offset = edge_index_2 + max_node_idx_1\n",
    "        edge_index = torch.cat([edge_index_1, edge_index_2_offset], dim=1)\n",
    "        batch = create_batch(torch.cat([sizes_1, sizes_2], dim=0))\n",
    "        feats, edge_index, batch = (\n",
    "            feats.to(self.args.device),\n",
    "            edge_index.to(self.args.device),\n",
    "            batch.to(self.args.device),\n",
    "        )\n",
    "        return feats, edge_index, batch\n",
    "\n",
    "    def forward(self, feats_1, edge_index_1, feats_2, edge_index_2, sizes_1, sizes_2):\n",
    "        self.layer_outputs = []\n",
    "        self.layer_cross_attentions = []\n",
    "        self.topk_outputs = []\n",
    "        self.mincut = []\n",
    "        self.norms_per_layer = []\n",
    "        self.attention_sums_per_layer = []\n",
    "\n",
    "        feats, edge_index, batch = self.combine_pair_embedding(\n",
    "            feats_1, edge_index_1, feats_2, edge_index_2, sizes_1, sizes_2\n",
    "        )\n",
    "        emb, _, _ = self.compute_emb(\n",
    "            feats, edge_index, batch, sizes_1, sizes_2, edge_index_1, edge_index_2\n",
    "        )\n",
    "        emb_1 = emb[: emb.shape[0] // 2, :]\n",
    "        emb_2 = emb[emb.shape[0] // 2 :, :]\n",
    "\n",
    "        best_acc1, best_acc2 = 0.0, 0.0\n",
    "        cluster1, cluster2 = None, None\n",
    "        layer1, layer2 = None, None\n",
    "        clusters = []\n",
    "\n",
    "        return emb_1, emb_2, cluster1, cluster2, layer1, layer2\n",
    "\n",
    "    def compute_metrics(self, emb_1, emb_2, labels):\n",
    "        distances = torch.norm(emb_1 - emb_2, p=2, dim=1)\n",
    "        loss = F.relu(self.margin - labels * (1 - distances)).mean()\n",
    "        predicted_similar = torch.where(\n",
    "            distances < self.args.margin,\n",
    "            torch.ones_like(labels),\n",
    "            -torch.ones_like(labels),\n",
    "        )\n",
    "        acc = (predicted_similar == labels).float().mean()\n",
    "        metrics = {\"loss\": loss, \"acc\": acc}\n",
    "        return metrics\n",
    "\n",
    "    def init_metric_dict(self):\n",
    "        return {\"acc\": -1, \"f1\": -1}\n",
    "\n",
    "    def has_improved(self, m1, m2):\n",
    "        return m1[\"acc\"] < m2[\"acc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, pairs, labels, batch_size, title):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    losses = []\n",
    "    accs = []\n",
    "\n",
    "    for i in range(len(pairs)):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        graph1, graph2 = pairs[i]\n",
    "        label = labels[i]\n",
    "\n",
    "        feats_1, edge_index_1 = graph1.x, graph1.edge_index\n",
    "        feats_2, edge_index_2 = graph2.x, graph2.edge_index\n",
    "        sizes_1 = torch.tensor([graph1.num_nodes])\n",
    "        sizes_2 = torch.tensor([graph2.num_nodes])\n",
    "\n",
    "        emb_1, emb_2, _, _, _, _ = model(\n",
    "            feats_1, edge_index_1, feats_2, edge_index_2, sizes_1, sizes_2\n",
    "        )\n",
    "\n",
    "        metrics = model.compute_metrics(emb_1, emb_2, torch.tensor([label]))\n",
    "        loss = metrics[\"loss\"]\n",
    "        acc = metrics[\"acc\"]\n",
    "\n",
    "        losses.append(loss)\n",
    "        accs.append(acc)\n",
    "\n",
    "        if i % batch_size == 0 and i > 0:\n",
    "            batch_loss = torch.mean(torch.stack(losses))\n",
    "            batch_acc = torch.mean(torch.stack(accs))\n",
    "            losses = []\n",
    "            accs = []\n",
    "            train_losses.append(batch_loss.detach().numpy())\n",
    "            train_accuracies.append(batch_acc.detach().numpy())\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    if train_accuracies[-1] > 0.0:\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        plt.title(title)\n",
    "\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(train_losses, label=\"Training Loss\")\n",
    "        plt.title(\"Loss over Epochs\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(train_accuracies, label=\"Training Accuracy\")\n",
    "        plt.title(\"Accuracy over Epochs\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.legend()\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    return train_accuracies[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCS:\n",
    "    def __init__(self, mp):\n",
    "        self.mp = mp\n",
    "        self.max_size = 0\n",
    "        self.all_mappings = []\n",
    "        self.unique_mappings = set()\n",
    "        self.visited = set()\n",
    "        self.time_limit = 5\n",
    "        self.start_time = None\n",
    "\n",
    "    def find_mcs(self, G1, G2):\n",
    "        self.max_size = 0\n",
    "        self.all_mappings = []\n",
    "        self.unique_mappings = set()\n",
    "        self.visited = set()\n",
    "        self.start_time = time.time()\n",
    "\n",
    "        G1_degrees = degree(G1.edge_index[0], G1.num_nodes)\n",
    "        G2_degrees = degree(G2.edge_index[0], G2.num_nodes)\n",
    "\n",
    "        nodes1 = list(range(G1.num_nodes))\n",
    "        nodes2 = list(range(G2.num_nodes))\n",
    "\n",
    "        for n1 in nodes1:\n",
    "            for n2 in nodes2:\n",
    "                if (n1, n2) in self.mp:\n",
    "                    M = {n1: n2}\n",
    "                    neighbors1 = set(G1.edge_index[1][G1.edge_index[0] == n1].tolist())\n",
    "                    neighbors2 = set(G2.edge_index[1][G2.edge_index[0] == n2].tolist())\n",
    "                    self.match(\n",
    "                        G1, G2, M, G1_degrees, G2_degrees, neighbors1, neighbors2\n",
    "                    )\n",
    "        return self.all_mappings\n",
    "\n",
    "    def match(self, G1, G2, M, G1_degrees, G2_degrees, neighbors1, neighbors2):\n",
    "        if time.time() - self.start_time > self.time_limit:\n",
    "            return\n",
    "\n",
    "        state = (frozenset(M.items()), frozenset(neighbors1), frozenset(neighbors2))\n",
    "        if state in self.visited:\n",
    "            return\n",
    "        self.visited.add(state)\n",
    "\n",
    "        edge_count = self.count_edges(M, G1, G2)\n",
    "\n",
    "        if len(M) > self.max_size or (\n",
    "            len(M) == self.max_size and edge_count > self.edge_count\n",
    "        ):\n",
    "            self.max_size = len(M)\n",
    "            self.edge_count = edge_count\n",
    "            self.all_mappings = [M.copy()]\n",
    "            self.unique_mappings = {self.canonical_form(M)}\n",
    "        elif len(M) == self.max_size and edge_count == self.edge_count:\n",
    "            canonical = self.canonical_form(M)\n",
    "            if canonical not in self.unique_mappings:\n",
    "                self.all_mappings.append(M.copy())\n",
    "                self.unique_mappings.add(canonical)\n",
    "\n",
    "        candidates1 = sorted(neighbors1, key=lambda n: -G1_degrees[n].item())\n",
    "        candidates2 = sorted(neighbors2, key=lambda n: -G2_degrees[n].item())\n",
    "\n",
    "        for n1 in candidates1:\n",
    "            if n1 not in M:\n",
    "                for n2 in candidates2:\n",
    "                    if n2 not in M.values() and self.feasible(n1, n2, M, G1, G2):\n",
    "                        M[n1] = n2\n",
    "                        new_neighbors1 = set(\n",
    "                            G1.edge_index[1][G1.edge_index[0] == n1].tolist()\n",
    "                        )\n",
    "                        new_neighbors2 = set(\n",
    "                            G2.edge_index[1][G2.edge_index[0] == n2].tolist()\n",
    "                        )\n",
    "                        neighbors1.update(new_neighbors1 - set(M.keys()))\n",
    "                        neighbors2.update(new_neighbors2 - set(M.values()))\n",
    "                        self.match(\n",
    "                            G1,\n",
    "                            G2,\n",
    "                            M,\n",
    "                            G1_degrees,\n",
    "                            G2_degrees,\n",
    "                            neighbors1,\n",
    "                            neighbors2,\n",
    "                        )\n",
    "                        del M[n1]\n",
    "                        neighbors1.difference_update(new_neighbors1)\n",
    "                        neighbors2.difference_update(new_neighbors2)\n",
    "\n",
    "    def feasible(self, n1, n2, M, G1, G2):\n",
    "        if not torch.equal(G1.x[n1], G2.x[n2]):\n",
    "            return False\n",
    "        if (n1, n2) not in self.mp:\n",
    "            return False\n",
    "\n",
    "        count1 = 0\n",
    "        count2 = 0\n",
    "\n",
    "        for neighbor in G1.edge_index[1][G1.edge_index[0] == n1]:\n",
    "            if neighbor.item() in M:\n",
    "                count1 += 1\n",
    "\n",
    "        for neighbor in G2.edge_index[1][G2.edge_index[0] == n2]:\n",
    "            if neighbor.item() in M.values():\n",
    "                count2 += 1\n",
    "\n",
    "        if count1 != count2:\n",
    "            return False\n",
    "\n",
    "        for neighbor in G1.edge_index[1][G1.edge_index[0] == n1]:\n",
    "            if (\n",
    "                neighbor.item() in M\n",
    "                and M[neighbor.item()]\n",
    "                not in G2.edge_index[1][G2.edge_index[0] == n2].tolist()\n",
    "            ):\n",
    "                return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def count_edges(self, M, G1, G2):\n",
    "        edge_count = 0\n",
    "        for u1, v1 in M.items():\n",
    "            for u2, v2 in M.items():\n",
    "                if u1 != u2:\n",
    "                    u1_v1_exists = (\n",
    "                        (G1.edge_index[0] == u1) & (G1.edge_index[1] == u2)\n",
    "                    ).any() or (\n",
    "                        (G1.edge_index[0] == u2) & (G1.edge_index[1] == u1)\n",
    "                    ).any()\n",
    "                    u2_v2_exists = (\n",
    "                        (G2.edge_index[0] == v1) & (G2.edge_index[1] == v2)\n",
    "                    ).any() or (\n",
    "                        (G2.edge_index[0] == v2) & (G2.edge_index[1] == v1)\n",
    "                    ).any()\n",
    "                    if u1_v1_exists and u2_v2_exists:\n",
    "                        edge_count += 1\n",
    "        return edge_count\n",
    "\n",
    "    def canonical_form(self, M):\n",
    "        G1_set = set(M.keys())\n",
    "        G2_set = set(M.values())\n",
    "        return (frozenset(G1_set), frozenset(G2_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embeddings_and_attention(\n",
    "    model, feats_1, edge_index_1, feats_2, edge_index_2, sizes_1, sizes_2\n",
    "):\n",
    "    model(feats_1, edge_index_1, feats_2, edge_index_2, sizes_1, sizes_2)\n",
    "    embeddings = model.layer_outputs\n",
    "    attentions = model.layer_cross_attentions\n",
    "    return embeddings, attentions\n",
    "\n",
    "\n",
    "def extract_dynamic_attention_nodes(attentions, threshold=0.1):\n",
    "    attention_nodes = []\n",
    "    softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "    for layer_idx, (cross_graph_attention, a_x, a_y) in enumerate(attentions):\n",
    "        dynamic_attention_nodes_1_to_2 = []\n",
    "        dynamic_attention_nodes_2_to_1 = []\n",
    "\n",
    "        a_x = a_x[0]\n",
    "        a_y = a_y[0]\n",
    "\n",
    "        assert a_x.shape[0] == a_y.shape[0]\n",
    "        assert a_x.shape[1] == a_y.shape[1]\n",
    "\n",
    "        # # Apply softmax normalization\n",
    "        # a_x = softmax(a_x)\n",
    "        # a_y = softmax(a_y.T).T\n",
    "\n",
    "        for i, x_attention in enumerate(a_x):\n",
    "            strong_attention_indices = (x_attention > threshold).nonzero(as_tuple=True)[\n",
    "                0\n",
    "            ]\n",
    "            dynamic_attention_nodes_1_to_2.append(strong_attention_indices.tolist())\n",
    "\n",
    "        for j, y_attention in enumerate(a_y.T):\n",
    "            strong_attention_indices = (y_attention > threshold).nonzero(as_tuple=True)[\n",
    "                0\n",
    "            ]\n",
    "            dynamic_attention_nodes_2_to_1.append(strong_attention_indices.tolist())\n",
    "\n",
    "        attention_nodes.append(\n",
    "            (dynamic_attention_nodes_1_to_2, dynamic_attention_nodes_2_to_1)\n",
    "        )\n",
    "\n",
    "    for i in range(len(attention_nodes)):\n",
    "        for j in range(i):\n",
    "            if attention_nodes[i] == attention_nodes[j]:\n",
    "                for k in range(len(attention_nodes[i][0])):\n",
    "                    attention_nodes[i][0][k] = []\n",
    "                for k in range(len(attention_nodes[i][1])):\n",
    "                    attention_nodes[i][1][k] = []\n",
    "                break\n",
    "\n",
    "    return attention_nodes\n",
    "\n",
    "\n",
    "def print_attentions(attention_nodes, d):\n",
    "    n_layers = len(attention_nodes)\n",
    "    max_length = max(\n",
    "        max(len(attn_1_to_2), len(attn_2_to_1))\n",
    "        for attn_1_to_2, attn_2_to_1 in attention_nodes\n",
    "    )\n",
    "\n",
    "    col_width = 30\n",
    "\n",
    "    if d == \"12\":\n",
    "        print(\" Graph 1 to Graph 2:\".ljust(73))\n",
    "    else:\n",
    "        print(\" Graph 2 to Graph 1:\".ljust(73))\n",
    "    print(\"=\" * 130)\n",
    "\n",
    "    for node_idx in range(max_length):\n",
    "        line = []\n",
    "\n",
    "        for layer_idx in range(n_layers):\n",
    "            if d == \"12\":\n",
    "                if node_idx < len(attention_nodes[layer_idx][0]):\n",
    "                    attn_1_to_2 = attention_nodes[layer_idx][0][node_idx]\n",
    "                    attn_1_to_2_str = f\"{node_idx}: {attn_1_to_2}\".ljust(col_width)\n",
    "                else:\n",
    "                    attn_1_to_2_str = \"\".ljust(col_width)\n",
    "\n",
    "                line.append(attn_1_to_2_str)\n",
    "\n",
    "            else:\n",
    "                if node_idx < len(attention_nodes[layer_idx][1]):\n",
    "                    attn_2_to_1 = attention_nodes[layer_idx][1][node_idx]\n",
    "                    attn_2_to_1_str = f\"{node_idx}: {attn_2_to_1}\".ljust(col_width)\n",
    "                else:\n",
    "                    attn_2_to_1_str = \"\".ljust(col_width)\n",
    "\n",
    "                line.append(attn_2_to_1_str)\n",
    "\n",
    "        g1_to_g2_str = \" | \".join(line)\n",
    "\n",
    "        print(f\"{g1_to_g2_str}\")\n",
    "\n",
    "    print(\"=\" * 130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_prototype(predicted_prototype, ground_truth_prototype, max_extra_nodes=3):\n",
    "    pred_nx = to_networkx(predicted_prototype, to_undirected=True)\n",
    "    gt_nx = to_networkx(ground_truth_prototype, to_undirected=True)\n",
    "    pred_nodes = set(pred_nx.nodes)\n",
    "    gt_nodes = set(gt_nx.nodes)\n",
    "    extra_nodes = pred_nodes - gt_nodes\n",
    "    num_extra_nodes = len(extra_nodes)\n",
    "    if num_extra_nodes > max_extra_nodes:\n",
    "        return False\n",
    "    subgraph_isomorphism = nx.is_isomorphic(gt_nx, pred_nx.subgraph(gt_nodes))\n",
    "    if not subgraph_isomorphism:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_subgraphs(pattern, graph1, graph2):\n",
    "    g1_nodes = set()\n",
    "    g2_nodes = set()\n",
    "    for g1_node, g2_node in pattern.items():\n",
    "        g1_nodes.add(g1_node)\n",
    "        g2_nodes.add(g2_node)\n",
    "\n",
    "    g1_node_map = {node: idx for idx, node in enumerate(g1_nodes)}\n",
    "    g2_node_map = {node: idx for idx, node in enumerate(g2_nodes)}\n",
    "\n",
    "    g1_edge_index = []\n",
    "    for edge in graph1.edge_index.t():\n",
    "        if edge[0].item() in g1_nodes and edge[1].item() in g1_nodes:\n",
    "            g1_edge_index.append(\n",
    "                [g1_node_map[edge[0].item()], g1_node_map[edge[1].item()]]\n",
    "            )\n",
    "\n",
    "    g2_edge_index = []\n",
    "    for edge in graph2.edge_index.t():\n",
    "        if edge[0].item() in g2_nodes and edge[1].item() in g2_nodes:\n",
    "            g2_edge_index.append(\n",
    "                [g2_node_map[edge[0].item()], g2_node_map[edge[1].item()]]\n",
    "            )\n",
    "\n",
    "    g1_subgraph = Data(\n",
    "        x=graph1.x[list(g1_nodes)],\n",
    "        edge_index=torch.tensor(g1_edge_index, dtype=torch.long).t().contiguous(),\n",
    "        original_node_ids=torch.tensor(list(g1_nodes), dtype=torch.long),\n",
    "    )\n",
    "    g2_subgraph = Data(\n",
    "        x=graph2.x[list(g2_nodes)],\n",
    "        edge_index=torch.tensor(g2_edge_index, dtype=torch.long).t().contiguous(),\n",
    "        original_node_ids=torch.tensor(list(g2_nodes), dtype=torch.long),\n",
    "    )\n",
    "\n",
    "    return g1_subgraph, g2_subgraph\n",
    "\n",
    "\n",
    "def mutual_pairs(attention_nodes, i=0):\n",
    "    outer_layer = attention_nodes[i]\n",
    "    g1_attention, g2_attention = outer_layer\n",
    "\n",
    "    mutual_pairs = []\n",
    "\n",
    "    for g1_node, g1_attends in enumerate(g1_attention):\n",
    "        for g2_node in g1_attends:\n",
    "            if g1_node in g2_attention[g2_node]:\n",
    "                pair = (g1_node, g2_node)\n",
    "                if pair not in mutual_pairs:\n",
    "                    mutual_pairs.append(pair)\n",
    "\n",
    "    random.shuffle(mutual_pairs)\n",
    "    return mutual_pairs\n",
    "\n",
    "\n",
    "def print_patterns(patterns, graph1, graph2):\n",
    "    for i in patterns:\n",
    "        g1_subgraph, g2_subgraph = create_subgraphs(i, graph1, graph2)\n",
    "\n",
    "        if nx.is_isomorphic(\n",
    "            to_networkx(g1_subgraph, to_undirected=True),\n",
    "            to_networkx(g2_subgraph, to_undirected=True),\n",
    "        ):\n",
    "\n",
    "            plot_mutag(\n",
    "                g1_subgraph,\n",
    "                g2_subgraph,\n",
    "                perm1=g1_subgraph.original_node_ids,\n",
    "                perm2=g2_subgraph.original_node_ids,\n",
    "            )\n",
    "\n",
    "\n",
    "def find_max_core_subgraph(graph_list):\n",
    "    def count_subgraph_occurrences(graph_list):\n",
    "        subgraph_counts = [0] * len(graph_list)\n",
    "        for i, graph1 in enumerate(graph_list):\n",
    "            g1 = to_networkx(graph1)\n",
    "            for j, graph2 in enumerate(graph_list):\n",
    "                if i != j:\n",
    "                    g2 = to_networkx(graph2)\n",
    "                    matcher = nx.algorithms.isomorphism.GraphMatcher(g2, g1)\n",
    "                    if matcher.subgraph_is_isomorphic():\n",
    "                        subgraph_counts[i] += 1\n",
    "        return subgraph_counts\n",
    "\n",
    "    subgraph_counts = count_subgraph_occurrences(graph_list)\n",
    "\n",
    "    max_count = max(subgraph_counts)\n",
    "    candidates = [i for i, count in enumerate(subgraph_counts) if count == max_count]\n",
    "    max_core_subgraph = max(candidates, key=lambda idx: graph_list[idx].num_nodes)\n",
    "\n",
    "    return graph_list[max_core_subgraph]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(G, title=None):\n",
    "    nx.draw(\n",
    "        to_networkx(G, to_undirected=True),\n",
    "        with_labels=False,\n",
    "        node_color=\"#3b8bc2\",\n",
    "        node_size=500,\n",
    "        edge_color=\"k\",\n",
    "        linewidths=2,\n",
    "        font_size=15,\n",
    "    )\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.load(\"datasets/mutag0.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "labels = [graph.y.item() for graph in dataset]\n",
    "\n",
    "train_indices, test_indices = train_test_split(\n",
    "    np.arange(len(dataset)), test_size=0.2, stratify=labels, random_state=42\n",
    ")\n",
    "\n",
    "train_set = [dataset[i] for i in train_indices]\n",
    "test_set = [dataset[i] for i in test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewArgs:\n",
    "    def __init__(self, dim, num_layers, margin, lr, batch_size, num_pairs):\n",
    "        self.dim = dim\n",
    "        self.feat_dim = dataset[0].x.shape[1]\n",
    "        self.num_layers = num_layers\n",
    "        self.margin = margin\n",
    "        self.lr = lr\n",
    "        self.n_classes = 2\n",
    "        self.batch_size = batch_size\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.n_clusters = 8\n",
    "        self.num_pairs = num_pairs\n",
    "\n",
    "\n",
    "hyperparams_list = [\n",
    "    # (16, 4, 0.5, 0.005, 32, 700),\n",
    "    # (16, 4, 0.5, 0.01, 32, 500),\n",
    "    (16, 5, 0.8, 0.1, 32, 500),\n",
    "    # (16, 7, 0.2, 0.001, 32, 500),\n",
    "    # (16, 7, 0.6, 0.01, 32, 300),\n",
    "    # (16, 7, 0.8, 0.001, 32, 700),\n",
    "    # (32, 4, 0.2, 0.01, 32, 300),\n",
    "]\n",
    "\n",
    "for hyperparams in hyperparams_list:\n",
    "    # hyperparams = (16, 7, 0.5, 0.05, 32, 500)\n",
    "    # hyperparams = (dim, layers, margin, lr, batch_size, num_pairs)\n",
    "    newargs = NewArgs(*hyperparams)\n",
    "    model = GraphMatchingNetwork(newargs)\n",
    "    optimizer = Adam(model.parameters(), lr=newargs.lr, weight_decay=1e-5)\n",
    "    pairs, labels = create_graph_pairs(dataset, newargs.num_pairs)\n",
    "    acc = train(\n",
    "        model,\n",
    "        optimizer,\n",
    "        pairs,\n",
    "        labels,\n",
    "        newargs.batch_size,\n",
    "        str(hyperparams),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dataset = {\n",
    "    \"class0\": [],\n",
    "    \"class1\": [],\n",
    "}\n",
    "\n",
    "for graph in test_set:\n",
    "    if graph.y.item() == 0:\n",
    "        split_dataset[\"class0\"].append(graph)\n",
    "    elif graph.y.item() == 1:\n",
    "        split_dataset[\"class1\"].append(graph)\n",
    "\n",
    "prototype = torch.load(\"mutag0_prototype.pt\", weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_graphs(graph1, graph2):\n",
    "    # c = \"class1\"\n",
    "    # idx1 = random.sample(range(len(split_dataset[c])), 1)[0]\n",
    "    # idx2 = random.sample(range(len(split_dataset[c])), 1)[0]\n",
    "    # graph1, graph2 = split_dataset[c][idx1], split_dataset[c][idx2]\n",
    "    model.eval()\n",
    "    feats_1, edge_index_1 = graph1.x, graph1.edge_index\n",
    "    feats_2, edge_index_2 = graph2.x, graph2.edge_index\n",
    "    sizes_1 = torch.tensor([len(graph1.x)])\n",
    "    sizes_2 = torch.tensor([len(graph2.x)])\n",
    "    model(feats_1, edge_index_1, feats_2, edge_index_2, sizes_1, sizes_2)\n",
    "\n",
    "    embeddings, attentions = extract_embeddings_and_attention(\n",
    "        model, feats_1, edge_index_1, feats_2, edge_index_2, sizes_1, sizes_2\n",
    "    )\n",
    "    return graph1, graph2, attentions\n",
    "\n",
    "\n",
    "def run_gmn(graph1, graph2, attentions, t=0.05):\n",
    "    largest_summary = None\n",
    "    most_nodes = 0\n",
    "    for i in range(model.args.num_layers):\n",
    "        attention_nodes = extract_dynamic_attention_nodes(attentions, threshold=t)\n",
    "        mp = mutual_pairs(attention_nodes, i)\n",
    "        vf2 = MCS(mp)\n",
    "        patterns = vf2.find_mcs(graph1, graph2)\n",
    "        if patterns != [] and len(patterns[0]) > 1:\n",
    "            pattern = patterns[0]\n",
    "\n",
    "            g1_subgraph, g2_subgraph = create_subgraphs(pattern, graph1, graph2)\n",
    "\n",
    "            if (\n",
    "                nx.is_isomorphic(\n",
    "                    to_networkx(g1_subgraph, to_undirected=True),\n",
    "                    to_networkx(g2_subgraph, to_undirected=True),\n",
    "                )\n",
    "                and len(pattern) > 2\n",
    "            ):\n",
    "                summary = Data(\n",
    "                    x=(g1_subgraph.x),\n",
    "                    edge_index=g1_subgraph.edge_index,\n",
    "                )\n",
    "\n",
    "                if len(pattern) > most_nodes:\n",
    "                    most_nodes = len(pattern)\n",
    "                    largest_summary = summary\n",
    "                    t_of_largest = t\n",
    "                    layer_of_largest = i + 1\n",
    "\n",
    "    return largest_summary\n",
    "\n",
    "\n",
    "# summaries = []\n",
    "# for i in range(1):\n",
    "#     graph1, graph2, attentions = sample_graphs()\n",
    "#     summary = run_gmn(graph1, graph2, attentions)\n",
    "#     summaries.append(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/st/cyh3v8ln22sdswp1s386w5vw0000gn/T/ipykernel_22094/1347121345.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pt_file = torch.load(file_path)\n",
      "/var/folders/st/cyh3v8ln22sdswp1s386w5vw0000gn/T/ipykernel_22094/1347121345.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pt_file = torch.load(file_path)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "gnnexplainer_graphs = []\n",
    "\n",
    "for file_name in os.listdir(\n",
    "    \"prototypes/gnn-model-explainer/gnnexplainer_mutag0_graphs\"\n",
    "):\n",
    "    if file_name.endswith(\".pt\"):\n",
    "        file_path = os.path.join(\n",
    "            \"prototypes/gnn-model-explainer/gnnexplainer_mutag0_graphs\", file_name\n",
    "        )\n",
    "        pt_file = torch.load(file_path)\n",
    "        gnnexplainer_graphs.append(pt_file)\n",
    "\n",
    "\n",
    "protgnn_graphs = []\n",
    "\n",
    "for file_name in os.listdir(\"prototypes/ProtGNN/protgnn_mutag0_graphs\"):\n",
    "    if file_name.endswith(\".pt\"):\n",
    "        file_path = os.path.join(\"prototypes/ProtGNN/protgnn_mutag0_graphs\", file_name)\n",
    "        pt_file = torch.load(file_path)\n",
    "        protgnn_graphs.append(pt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutag0_graphs = []\n",
    "\n",
    "for i in range(90):\n",
    "    mutag0_graphs.append(\n",
    "        (\n",
    "            to_networkx(gnnexplainer_graphs[i][0]),\n",
    "            to_networkx(protgnn_graphs[i][1]),\n",
    "            to_networkx(gnnexplainer_graphs[i][1]),\n",
    "            prototype,\n",
    "        )\n",
    "    )\n",
    "\n",
    "torch.save(mutag0_graphs, \"mutag0_other_prototypes.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "gnnexplainer_prototypes = [g[1] for g in gnnexplainer_graphs]\n",
    "protgnn_prototypes = [g[1] for g in protgnn_graphs]\n",
    "\n",
    "print(sum(1 for graph in protgnn_prototypes if evaluate_prototype(graph, prototype)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(5, 50), (27, 11), (14, 42), (88, 48), (44, 81), (15, 37), (89, 45), (1, 80), (29, 64), (51, 74), (55, 23), (12, 3), (33, 13), (23, 34), (54, 34), (25, 86), (82, 45), (57, 56), (38, 4), (77, 67), (0, 4), (65, 33), (79, 12), (38, 42), (64, 72), (36, 69), (50, 47), (74, 54), (22, 48), (60, 68), (24, 60), (52, 18), (35, 53), (24, 40), (39, 14), (58, 9), (20, 88), (72, 29), (3, 84), (87, 10), (41, 52), (78, 6), (73, 66), (22, 77), (17, 28), (83, 20), (35, 16), (68, 21), (8, 62), (7, 71), (70, 89), (86, 61), (85, 18), (59, 40), (76, 85), (19, 28), (43, 0), (82, 32), (7, 2), (53, 5), (30, 47), (26, 16), (2, 11), (15, 73), (87, 58), (10, 75), (81, 51), (21, 75), (30, 56), (67, 39), (25, 17), (37, 26), (1, 9), (70, 84), (76, 13), (79, 8), (19, 66), (31, 6), (83, 55), (59, 63), (65, 57), (31, 44), (46, 61), (27, 62), (46, 32), (43, 80), (69, 41), (63, 71), (78, 49), (36, 49)]\n"
     ]
    }
   ],
   "source": [
    "numbers = list(range(90)) * 2\n",
    "random.shuffle(numbers)\n",
    "random_pairs = [(numbers[i], numbers[i + 1]) for i in range(0, len(numbers), 2)]\n",
    "\n",
    "print(random_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = []\n",
    "\n",
    "for p1, p2 in random_pairs:\n",
    "    pairs.append((split_dataset[\"class1\"][p1], split_dataset[\"class1\"][p2]))\n",
    "\n",
    "summaries = []\n",
    "for g1, g2 in pairs:\n",
    "    graph1, graph2, attentions = sample_graphs(g1, g2)\n",
    "    summary = run_gmn(graph1, graph2, attentions)\n",
    "    summaries.append(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "print(sum(1 for graph in summaries if graph and evaluate_prototype(graph, prototype)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save((summaries, mutag0_graphs), \"mutag0_prototypes.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
