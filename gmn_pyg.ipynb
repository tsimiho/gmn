{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.nn import Linear\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import Adam\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import BatchNorm, MessagePassing, TopKPooling\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "from torch_geometric.utils import (\n",
    "    dense_to_sparse,\n",
    "    is_undirected,\n",
    "    to_networkx,\n",
    "    to_undirected,\n",
    ")\n",
    "from torch_scatter import scatter_mean\n",
    "\n",
    "from custom.args import grey, purple\n",
    "from custom.dataset import GraphDataset, create_dataset\n",
    "from custom.utils import *\n",
    "from custom.model import GraphMatchingNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TUDataset(\n",
    "    root=\"data\", name=\"MUTAG\", use_node_attr=True, transform=NormalizeFeatures()\n",
    ")\n",
    "\n",
    "small_graphs, medium_graphs, large_graphs, classes = analyze_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, pairs, labels, batch_size, title=\"\"):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    losses = []\n",
    "    accs = []\n",
    "\n",
    "    def get_params(model):\n",
    "        return {name: param.clone() for name, param in model.named_parameters()}\n",
    "\n",
    "    initial_params = get_params(model)\n",
    "\n",
    "    for i in range(len(pairs)):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        graph1, graph2 = pairs[i]\n",
    "        label = labels[i]\n",
    "\n",
    "        feats_1, edge_index_1 = graph1.x, graph1.edge_index\n",
    "        feats_2, edge_index_2 = graph2.x, graph2.edge_index\n",
    "        sizes_1 = torch.tensor([graph1.num_nodes])\n",
    "        sizes_2 = torch.tensor([graph2.num_nodes])\n",
    "\n",
    "        emb_1, emb_2, _, _ = model(\n",
    "            feats_1, edge_index_1, feats_2, edge_index_2, sizes_1, sizes_2\n",
    "        )\n",
    "\n",
    "        metrics = model.compute_metrics(emb_1, emb_2, torch.tensor([label]))\n",
    "        loss = metrics[\"loss\"]\n",
    "        acc = metrics[\"acc\"]\n",
    "\n",
    "        losses.append(loss)\n",
    "        accs.append(acc)\n",
    "\n",
    "        if i % batch_size == 0 and i > 0:\n",
    "            batch_loss = torch.mean(torch.stack(losses))\n",
    "            batch_acc = torch.mean(torch.stack(accs))\n",
    "            losses = []\n",
    "            accs = []\n",
    "            train_losses.append(batch_loss.detach().numpy())\n",
    "            train_accuracies.append(batch_acc.detach().numpy())\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            # if i % 100 * batch_size == 0:\n",
    "            #     print(\n",
    "            #         f\"Epoch: {i} - Loss: {batch_loss.item():.4f}, Acc: {batch_acc:.4f}\"\n",
    "            #     )\n",
    "\n",
    "    trained_params = get_params(model)\n",
    "\n",
    "    # for name in initial_params:\n",
    "    #     initial_param = initial_params[name]\n",
    "    #     trained_param = trained_params[name]\n",
    "    #     if not torch.equal(initial_param, trained_param):\n",
    "    #         print(f\"Parameter {name} has changed.\")\n",
    "    #     else:\n",
    "    #         print(f\"Parameter {name} has NOT changed.\")\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.suptitle(title)\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label=\"Training Loss\")\n",
    "    plt.title(\"Loss over Epochs\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_accuracies, label=\"Training Accuracy\")\n",
    "    plt.title(\"Accuracy over Epochs\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_32 = [\n",
    "    (32, 4, 0.4, 0.001, 64, 500),\n",
    "    (32, 5, 0.1, 0.01, 64, 3000),\n",
    "    (32, 5, 0.2, 0.01, 16, 3000),\n",
    "    (32, 5, 0.2, 0.01, 32, 3000),\n",
    "    (32, 5, 0.4, 0.01, 32, 1000),\n",
    "    (32, 6, 0.1, 0.0001, 32, 2000),\n",
    "    (32, 6, 0.1, 0.0001, 64, 3000),\n",
    "    (32, 6, 0.1, 0.0001, 128, 500),\n",
    "    (32, 6, 0.2, 0.01, 16, 3000),\n",
    "    (32, 6, 0.2, 0.001, 64, 500),\n",
    "    (32, 6, 0.2, 0.0001, 32, 2000),\n",
    "    (32, 6, 0.4, 0.001, 128, 2000),\n",
    "    (32, 6, 0.5, 0.001, 16, 3000),\n",
    "    (32, 6, 0.5, 0.0001, 128, 3000),\n",
    "    (32, 7, 0.2, 0.01, 16, 3000),\n",
    "    (32, 7, 0.2, 0.01, 64, 500),\n",
    "    (32, 7, 0.2, 0.01, 128, 3000),\n",
    "    (32, 7, 0.2, 0.001, 128, 500),\n",
    "    (32, 7, 0.2, 0.0001, 64, 3000),\n",
    "    (32, 7, 0.3, 0.01, 64, 1000),\n",
    "    (32, 7, 0.3, 0.0001, 32, 1000),\n",
    "    (32, 7, 0.4, 0.01, 16, 2000),\n",
    "    (32, 7, 0.4, 0.0001, 32, 500),\n",
    "    (32, 7, 0.4, 0.0001, 64, 2000),\n",
    "    (32, 7, 0.4, 0.0001, 128, 3000),\n",
    "    (32, 7, 0.5, 0.01, 32, 500),\n",
    "    (32, 7, 0.5, 0.01, 32, 3000),\n",
    "    (32, 7, 0.5, 0.01, 128, 1000),\n",
    "    (32, 7, 0.5, 0.0001, 32, 500),\n",
    "    (32, 7, 0.5, 0.0001, 128, 3000),\n",
    "    (32, 7, 1, 0.01, 64, 1000),\n",
    "    (32, 7, 1, 0.001, 128, 1000),\n",
    "    (32, 7, 1, 0.001, 128, 2000),\n",
    "    (32, 8, 0.2, 0.01, 128, 1000),\n",
    "    (32, 8, 0.2, 0.0001, 32, 2000),\n",
    "    (32, 8, 0.3, 0.01, 64, 2000),\n",
    "    (32, 8, 0.3, 0.0001, 64, 500),\n",
    "    (32, 8, 0.3, 0.0001, 64, 1000),\n",
    "    (32, 8, 0.4, 0.01, 16, 3000),\n",
    "    (32, 8, 0.4, 0.0001, 128, 2000),\n",
    "    (32, 8, 0.5, 0.01, 32, 3000),\n",
    "    (32, 8, 0.5, 0.01, 64, 3000),\n",
    "    (32, 8, 0.5, 0.001, 32, 2000),\n",
    "    (32, 8, 0.5, 0.001, 64, 3000),\n",
    "    (32, 8, 0.5, 0.001, 128, 500),\n",
    "    (32, 8, 0.5, 0.0001, 32, 2000),\n",
    "    (32, 8, 1, 0.001, 32, 500),\n",
    "    (32, 8, 1, 0.0001, 64, 2000),\n",
    "    (32, 8, 1, 0.0001, 64, 3000),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, title=\"\", layers=3):\n",
    "    class_clusters = []\n",
    "    class_accs = []\n",
    "    for i in range(dataset.num_classes):\n",
    "        c = f\"class_{str(i)}\"\n",
    "        idx1 = random.sample(range(len(classes[c])), 1)[0]\n",
    "        idx2 = random.sample(range(len(classes[c])), 1)[0]\n",
    "        graph1, graph2 = classes[c][idx1], classes[c][idx2]\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        feats_1, edge_index_1 = graph1.x, graph1.edge_index\n",
    "        feats_2, edge_index_2 = graph2.x, graph2.edge_index\n",
    "        sizes_1 = torch.tensor([len(graph1.x)])\n",
    "        sizes_2 = torch.tensor([len(graph2.x)])\n",
    "        _, _, cluster1, cluster2 = model(\n",
    "            feats_1, edge_index_1, feats_2, edge_index_2, sizes_1, sizes_2\n",
    "        )\n",
    "\n",
    "        clusters = []\n",
    "        accs = []\n",
    "\n",
    "        for i in range(len(model.topk_outputs)):\n",
    "            (\n",
    "                (x_pooled_1, edge_index_pooled_1, perm1),\n",
    "                (x_pooled_2, edge_index_pooled_2, perm2),\n",
    "            ) = model.topk_outputs[i]\n",
    "            clusters.append(\n",
    "                (\n",
    "                    Data(x=x_pooled_1, edge_index=edge_index_pooled_1),\n",
    "                    Data(x=x_pooled_2, edge_index=edge_index_pooled_2),\n",
    "                )\n",
    "            )\n",
    "            accs.append(\n",
    "                (\n",
    "                    len(set(range(8)) & set(perm1.tolist())),\n",
    "                    len(set(range(8)) & set(perm2.tolist())),\n",
    "                )\n",
    "            )\n",
    "\n",
    "        acc = list(itertools.chain.from_iterable(zip(*accs)))\n",
    "        class_accs.extend(acc)\n",
    "\n",
    "        cs = list(itertools.chain.from_iterable(zip(*clusters)))\n",
    "        class_clusters.extend(cs)\n",
    "\n",
    "    print(len(class_clusters))\n",
    "    plot_all_classes(class_clusters, class_accs, title, layers, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewArgs:\n",
    "    def __init__(self, dim, num_layers, margin, lr, batch_size, num_pairs):\n",
    "        self.dim = dim\n",
    "        self.feat_dim = dataset.num_features\n",
    "        self.num_layers = num_layers\n",
    "        self.margin = margin\n",
    "        self.lr = lr\n",
    "        self.n_classes = dataset.num_classes\n",
    "        self.batch_size = batch_size\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.n_clusters = 8\n",
    "        self.num_pairs = num_pairs\n",
    "\n",
    "\n",
    "dims = [32]\n",
    "num_layers_s = [3, 4, 5, 6, 7, 8]\n",
    "margins = [0.1, 0.2, 0.3, 0.4, 0.5, 1]\n",
    "lrs = [0.01, 0.001, 0.0001]\n",
    "batch_sizes = [16, 32, 64, 128]\n",
    "num_pairs_s = [500, 1000, 2000, 3000]\n",
    "\n",
    "for hyperparams in itertools.product(\n",
    "    dims, num_layers_s, margins, lrs, batch_sizes, num_pairs_s\n",
    "):\n",
    "    newargs = NewArgs(*hyperparams)\n",
    "    m = GraphMatchingNetwork(newargs)\n",
    "    o = Adam(m.parameters(), lr=newargs.lr, weight_decay=1e-5)\n",
    "    p, l = create_graph_pairs(dataset, newargs.num_pairs)\n",
    "    train(m, o, p, l, newargs.batch_size, str(hyperparams))\n",
    "    # test(m, layers=newargs.num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.dim = 32\n",
    "        self.feat_dim = dataset.num_features\n",
    "        self.num_layers = 3\n",
    "        self.margin = 0.5\n",
    "        self.lr = 0.01\n",
    "        self.n_classes = dataset.num_classes\n",
    "        self.batch_size = 128\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.n_clusters = 8\n",
    "        self.num_pairs = 3000\n",
    "\n",
    "\n",
    "args = Args()\n",
    "\n",
    "pairs, labels = create_graph_pairs(dataset, args.num_pairs)\n",
    "model = GraphMatchingNetwork(args).to(args.device)\n",
    "optimizer = Adam(model.parameters(), lr=args.lr, weight_decay=1e-5)\n",
    "train(model, optimizer, pairs, labels, args.batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
