{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../gmn_config/'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from gmn_config.graph_utils import *\n",
    "\n",
    "from gmn_config.evaluation import compute_similarity, auc\n",
    "from gmn_config.loss import pairwise_loss, triplet_loss\n",
    "from gmn_config.gmn_utils import *\n",
    "from gmn_config.configure_cosine import *\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "\n",
    "config = get_default_config()\n",
    "\n",
    "# torch.manual_seed(seed + 2)\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "gmn, optimizer = build_model(config, 64, 4)\n",
    "gmn.load_state_dict(torch.load(\"../gmn_config/model64_5.pth\"))\n",
    "gmn.to(device)\n",
    "gmn.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import Node2Vec\n",
    "import torch_geometric.transforms as T\n",
    "from sklearn.cluster import KMeans\n",
    "from math import ceil\n",
    "from torch_geometric import utils\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import os\n",
    "import os.path as osp\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from utils.eval_metrics import *\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'Cora'\n",
    "path = osp.join('..', 'data', dataset)\n",
    "dataset = Planetoid(path, dataset, transform=T.NormalizeFeatures())\n",
    "data = dataset[0]\n",
    "\n",
    "delta = 0.85\n",
    "edge_index, edge_weight = utils.get_laplacian(data.edge_index, data.edge_weight, normalization='sym')\n",
    "L = utils.to_dense_adj(edge_index, edge_attr=edge_weight)\n",
    "A = torch.eye(data.num_nodes) - delta*L\n",
    "data.edge_index, data.edge_weight = utils.dense_to_sparse(A)\n",
    "original_data = Data(x=reduce_dimensions(data.x.numpy()), edge_index=data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = Node2Vec(data.edge_index, embedding_dim=64, walk_length=20, context_size=10, walks_per_node=5,\n",
    "                 num_negative_samples=1, p=1.0, q=1.0, sparse=True).to(device)\n",
    "batch_size = 64\n",
    "loader = model.loader(batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "optimizer = torch.optim.SparseAdam(model.parameters(), lr=0.001)\n",
    "original_data = Data(x=reduce_dimensions(data.x.numpy()), edge_index=data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for pos_rw, neg_rw in loader:\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.loss(pos_rw.to(device), neg_rw.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "for epoch in range(1, 51):\n",
    "    loss = train()\n",
    "    model.eval()\n",
    "    z = model().cpu().detach().numpy()\n",
    "    kmeans = KMeans(n_clusters=len(set(data.y.numpy())), n_init=10)\n",
    "    predicted_clusters = kmeans.fit_predict(z)\n",
    "    predicted_clusters_tensor = torch.tensor(predicted_clusters, dtype=torch.long)\n",
    "    cluster_centers = torch.tensor(kmeans.cluster_centers_, dtype=torch.float)\n",
    "    num_clusters = cluster_centers.size(0)\n",
    "    cluster_adj_matrix = np.zeros((num_clusters, num_clusters))\n",
    "\n",
    "    for i in range(data.edge_index.size(1)):\n",
    "        src, dest = data.edge_index[:, i]\n",
    "        src_cluster = predicted_clusters[src.item()]\n",
    "        dest_cluster = predicted_clusters[dest.item()]\n",
    "        if src_cluster != dest_cluster:\n",
    "            cluster_adj_matrix[src_cluster, dest_cluster] = 1\n",
    "            cluster_adj_matrix[dest_cluster, src_cluster] = 1\n",
    "\n",
    "    cluster_edge_index = torch.tensor(np.array(np.nonzero(cluster_adj_matrix)), dtype=torch.long)\n",
    "    clustered_data = torch_geometric.data.Data(x=cluster_centers, edge_index=cluster_edge_index)\n",
    "    sim = similarity(gmn, config, original_data, clustered_data)\n",
    "    acc, nmi, ari = eval_metrics(data.y, predicted_clusters_tensor)\n",
    "    if (epoch % 5 == 0):\n",
    "        print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}, NMI: {nmi}, ACC: {acc}, ARI: {ari:.3f}, SIM: {sim:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "z = model().cpu().detach().numpy()\n",
    "\n",
    "kmeans = KMeans(n_clusters=dataset.num_classes, n_init=10)\n",
    "predicted_clusters = kmeans.fit_predict(z)\n",
    "\n",
    "cluster_centers = torch.tensor(kmeans.cluster_centers_, dtype=torch.float)\n",
    "num_clusters = cluster_centers.size(0)\n",
    "cluster_adj_matrix = np.zeros((num_clusters, num_clusters))\n",
    "\n",
    "for i in range(data.edge_index.size(1)):\n",
    "    src, dest = data.edge_index[:, i]\n",
    "    src_cluster = predicted_clusters[src.item()]\n",
    "    dest_cluster = predicted_clusters[dest.item()]\n",
    "    if src_cluster != dest_cluster:\n",
    "        cluster_adj_matrix[src_cluster, dest_cluster] = 1\n",
    "        cluster_adj_matrix[dest_cluster, src_cluster] = 1\n",
    "\n",
    "cluster_edge_index = torch.tensor(np.array(np.nonzero(cluster_adj_matrix)), dtype=torch.long)\n",
    "clustered_data = torch_geometric.data.Data(x=cluster_centers, edge_index=cluster_edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
